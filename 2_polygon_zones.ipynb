{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbce24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import supervision as sv\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from ultralytics import YOLO\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shapely\n",
    "import torch\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190e4d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME = 'c:\\\\Repos\\\\inz'\n",
      "torch.cuda.is_available() = True\n"
     ]
    }
   ],
   "source": [
    "HOME = os.getcwd()\n",
    "print(f\"{HOME = }\")\n",
    "print(f\"{torch.cuda.is_available() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26900feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')  # Load a pretrained YOLO model https://docs.ultralytics.com/usage/python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715c37aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r'C:\\Repos\\inz\\src_vids\\test_lagrange_23.mkv'\n",
    "target_path = r'C:\\Repos\\inz\\runs\\test\\test_polygon_zone_lagrange_23.mkv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40f32dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {1:'bicycle', 2:'car', 3:'motorcycle', 5:'bus', 7:'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5451b44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoInfo(width=1920, height=1080, fps=30, total_frames=717)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_info = sv.VideoInfo.from_video_path(video_path)\n",
    "video_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c596f268",
   "metadata": {},
   "source": [
    "# Draw polygon zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "266648ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(cmap=\"Pastel1\", n_colors=9):\n",
    "    \"\"\"Color generator. Loops colors if end is reached.\n",
    "\n",
    "    Args:\n",
    "\n",
    "        cmap (str, optional): Cmap name. cmap from matplotlib.pyplot.get_cmap(cmap, n_colors). Defaults to 'Pastel1'.\n",
    "\n",
    "        n_colors (int, optional): Number of colors. n_colors from matplotlib.pyplot.get_cmap(cmap, n_colors). Defaults to 9.\n",
    "\n",
    "    Yields:\n",
    "\n",
    "        list: List of r, g, b values. Eg.: (255, 255, 255)\n",
    "    \"\"\"\n",
    "    cmap = plt.get_cmap(cmap, n_colors)\n",
    "    all_colors = []\n",
    "    for i in range(n_colors):\n",
    "        all_colors.append([c * 255 for c in cmap(0 + (i / n_colors))])\n",
    "    n = 0\n",
    "    while True:\n",
    "        yield all_colors[n % n_colors][:-1]\n",
    "        n += 1\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "status, first_frame = cap.read()\n",
    "cap.release()\n",
    "good_image = first_frame.copy()\n",
    "color_gen = get_color()\n",
    "color = next(color_gen)\n",
    "zones = dict()\n",
    "curr_zone_id = 0\n",
    "\n",
    "\n",
    "def draw_zones(event, x, y, flags, param):\n",
    "    global zones, curr_zone_id, good_image, first_frame, color\n",
    "    # Add next point to current polygon zone\n",
    "    if flags == cv2.EVENT_FLAG_CTRLKEY + cv2.EVENT_FLAG_LBUTTON:\n",
    "        first_frame = good_image.copy()\n",
    "        if curr_zone_id in zones:\n",
    "            zones[curr_zone_id].append((x, y))\n",
    "        else:\n",
    "            zones[curr_zone_id] = [(x, y)]\n",
    "        try:\n",
    "            cv2.polylines(first_frame, np.array([zones[curr_zone_id]]), True, color, 5)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    # Delete last added point from current polygon zone\n",
    "    elif flags == cv2.EVENT_FLAG_CTRLKEY + cv2.EVENT_FLAG_RBUTTON:\n",
    "        first_frame = good_image.copy()\n",
    "        try:\n",
    "            zones[curr_zone_id].pop(-1)\n",
    "        except IndexError:\n",
    "            zones.pop(curr_zone_id, None)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        try:\n",
    "            cv2.polylines(first_frame, np.array([zones[curr_zone_id]]), True, color, 5)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    # Save current polygon zone and move to next one\n",
    "    elif flags == cv2.EVENT_FLAG_MBUTTON:\n",
    "        good_image = first_frame\n",
    "        curr_zone_id += 1\n",
    "        color = next(color_gen)\n",
    "    cv2.imshow(\"drawing polygon zones\", first_frame)\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"drawing polygon zones\")\n",
    "cv2.setMouseCallback(\"drawing polygon zones\", draw_zones)\n",
    "while True:\n",
    "    cv2.imshow(\"drawing polygon zones\", first_frame)\n",
    "    if cv2.waitKey(10) == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d1c0188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(572, 679), (960, 516), (251, 453)],\n",
       " 1: [(187, 978), (189, 978), (819, 748), (820, 748), (954, 1000), (953, 1000)],\n",
       " 2: [(1791, 776),\n",
       "  (1790, 776),\n",
       "  (1789, 775),\n",
       "  (1788, 774),\n",
       "  (1675, 685),\n",
       "  (1815, 596)],\n",
       " 3: [(1323, 482), (1322, 481), (1265, 305), (1724, 318), (1745, 527)]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4904e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_info = VideoInfo.from_video_path(video_path)\n",
    "# print(\"TUTAJ: \", video_info)\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "# out = cv2.VideoWriter(target_path, cv2.VideoWriter_fourcc(*'DIVX'), video_info.fps, video_info.resolution_wh)\n",
    "# frame_no = 0\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         cv2.destroyAllWindows()\n",
    "#         break\n",
    "\n",
    "#     results = model(source=frame[440:,:], classes=[1, 2, 3, 5, 7], imgsz=640, conf=0.25, show=False)[0]  # (source=frame[440:,:]\n",
    "#     detections = []\n",
    "#     for r in results.boxes.data.tolist():\n",
    "#         x1, y1, x2, y2, score, class_id = r\n",
    "#         detections.append([int(x1 + 0.5), int(y1 + 0.5), int(x2 + 0.5), int(y2 + 0.5), score, int(class_id)])\n",
    "\n",
    "#     # display current frame\n",
    "#     cv2.imshow(f\"frame {0}\", frame)\n",
    "#     if cv2.waitKey(30) & 0xFF == 27:\n",
    "#         cv2.destroyAllWindows()\n",
    "#         break\n",
    "    \n",
    "#     frame_no += 1\n",
    "#     out.write(frame)\n",
    "\n",
    "# cap.release()\n",
    "# out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c4321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_info = sv.VideoInfo.from_video_path(video_path)\n",
    "# with sv.VideoSink(target_path, video_info) as s:\n",
    "#     for frame in tqdm(sv.get_video_frames_generator(video_path), total=video_info.total_frames-2):\n",
    "#         result = model(source=frame, classes=list(classes.keys()), imgsz=640, conf=0.25, show=False)[0]  # (source=frame[440:,:]\n",
    "\n",
    "#         # detections = []\n",
    "#         # for r in results.boxes.data.tolist():\n",
    "#         #     x1, y1, x2, y2, score, class_id = r\n",
    "#         #     detections.append([int(x1 + 0.5), int(y1 + 0.5), int(x2 + 0.5), int(y2 + 0.5), score, int(class_id)])\n",
    "#         # for d in detections:\n",
    "#         #     # if (d[1]+d[3])/2 < 440:\n",
    "#         #     cv2.rectangle(frame, (d[0],d[1]), (d[2],d[3]), (0,0,255))\n",
    "\n",
    "#         detections = sv.Detections.from_yolov8(result)\n",
    "#         box_annotator = sv.BoxAnnotator(color=sv.ColorPalette.default(),  # sv.ColorPalette.default()\n",
    "#                                         thickness=2,\n",
    "#                                         text_color=sv.Color.black(),\n",
    "#                                         text_scale=0.5,\n",
    "#                                         text_thickness=1,\n",
    "#                                         text_padding=5)\n",
    "#         labels = [\n",
    "#             f\"{classes[class_id]} {confidence:0.2f}\"\n",
    "#             for _, _, confidence, class_id, _ in detections\n",
    "#         ]\n",
    "#         annotated_frame = box_annotator.annotate(\n",
    "#             scene=frame,  # scene=frame.copy()\n",
    "#             detections=detections,\n",
    "#             labels=labels\n",
    "#         )\n",
    "\n",
    "#         s.write_frame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85050354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Whole Video\n",
    "results = model.track(source=video_path,\n",
    "                      stream=True,  # stream=True should be used for long videos to avoid OOM errors\n",
    "                      tracker='botsort.yaml',  # custombotsort.yaml\n",
    "                      persist=True,\n",
    "                      classes=list(classes.keys()),\n",
    "                      imgsz=640,\n",
    "                      conf=0.25,\n",
    "                      iou=0.7,\n",
    "                      project=r'C:\\Repos\\inz\\runs',\n",
    "                      name='hway_test_line',\n",
    "                      save=True,\n",
    "                      show=False,\n",
    "                      line_width=3,\n",
    "                      # save_txt=True,\n",
    "                      # save_conf=True,\n",
    "                      # agnostic_nms=False,\n",
    "                      # visualize=False,\n",
    "                      # save_crop=True,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19077c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Whole Video and create DataFrame\n",
    "LINE_START = Point(30, 800)\n",
    "LINE_END = Point(1920-30, 800)\n",
    "line_counter = LineZone(start=LINE_START, end=LINE_END)\n",
    "line_annotator = LineZoneAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
    "\n",
    "temp_table = []  # list with data for df creation\n",
    "\n",
    "video_info = sv.VideoInfo.from_video_path(video_path)\n",
    "with sv.VideoSink(target_path, video_info) as s:\n",
    "    for frame, r in enumerate(results):\n",
    "        # detections = sv.Detections.from_yolov8(r)\n",
    "        detections = sv.Detections(xyxy=r.boxes.xyxy.cpu().numpy(),\n",
    "                                    confidence=r.boxes.conf.cpu().numpy(),\n",
    "                                    class_id=r.boxes.cls.cpu().numpy().astype(int),\n",
    "                                    tracker_id=r.boxes.id.cpu().numpy().astype(int))\n",
    "\n",
    "        # bboxes graphics settings\n",
    "        box_annotator = sv.BoxAnnotator(color=sv.ColorPalette.default(),  # sv.ColorPalette.default()\n",
    "                                        thickness=2,\n",
    "                                        text_color=sv.Color.black(),\n",
    "                                        text_scale=0.5,\n",
    "                                        text_thickness=1,\n",
    "                                        text_padding=5)\n",
    "        labels = [\n",
    "            f\"id:{tracker_id} {classes[class_id]} {confidence:0.2f}\"\n",
    "            for _, _, confidence, class_id, tracker_id in detections\n",
    "        ]\n",
    "\n",
    "        # updating line counter\n",
    "        # line_counter.update(detections=detections)\n",
    "        line_counter.trigger(detections=detections)\n",
    "\n",
    "        # annotating bboxes\n",
    "        annotated_frame = box_annotator.annotate(\n",
    "            scene=r.orig_img,  # scene=frame.copy()\n",
    "            detections=detections,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        # annotating the line        \n",
    "        # line_annotator.annotate(frame=r.orig_img, line_counter=line_counter)\n",
    "        line_annotator.annotate(frame=annotated_frame, line_counter=line_counter)\n",
    "\n",
    "        # write processed frame to video\n",
    "        s.write_frame(r.orig_img)\n",
    "\n",
    "        # append useful data to temp_table\n",
    "        for row in r.boxes.data.cpu().tolist():\n",
    "            x1, y1, x2, y2, id, conf, class_no = row\n",
    "            temp_table.append([int(id), int(class_no), conf, frame, x1, y1, x2, y2])\n",
    "\n",
    "# create df\n",
    "df = pd.DataFrame(temp_table, columns=['id', 'class_no', 'confidence', 'frame', 'x1', 'y1', 'x2', 'y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e05979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bef7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = df['class_no'].unique()\n",
    "frames = {class_no:[None]*len(unique_classes) for class_no in df['frame'].unique()}\n",
    "for i, class_no in enumerate(unique_classes):\n",
    "    series = df[df['class_no']==class_no]['frame'].value_counts()\n",
    "    for frame, count in zip(series.index, series.values):\n",
    "        frames[frame][i] = count\n",
    "df_class_counts = pd.DataFrame.from_dict(frames, orient='index', columns=[classes[n] for n in unique_classes])  # , dtype={c:int for c in unique_classes}\n",
    "df_class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1519b80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inz",
   "language": "python",
   "name": "inz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
